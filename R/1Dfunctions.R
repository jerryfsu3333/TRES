## The core functions for 1D algorithm based functions: OptM1D, manifold1D, oneD_bic, TRRdim

##################################################
#         1D optimization function               #
##################################################
fun1D <- function(W, M, U){
  f <- log(t(W) %*% M %*% W) + log(t(W) %*% chol2inv(chol(M+U)) %*% W)
  df <- 2*(M %*% W/(as.numeric(t(W) %*% M %*% W))+
             solve(M+U) %*% W/(as.numeric(t(W) %*% chol2inv(chol(M+U)) %*% W)))
  # list(F = f, G = df)
  ##
  list(FF = f, G = df)
  ##
}

##################################################
#    get initial value for 1D algorithm          #
##################################################
get_ini1D <- function(M, U){
  p <- dim(U)[2]
  v1 <- eigen(M)$vectors
  v2 <- eigen(M+U)$vectors
  v <- cbind(v1, v2)
  ##
  index <- v[1,] < 0
  v[,index] <- -v[,index]
  ##
  W0 <- Re(v[, 1]) ## Ensure the real number
  # Fw0 <- fun1D(W0, M, U)$F
  ##
  Fw0 <- fun1D(W0, M, U)$FF
  ##
  for (i in 2:(2*p)) {
    W <- Re(v[, i])
    # Fw <- fun1D(W, M, U)$F
    ##
    Fw <- fun1D(W, M, U)$FF
    ##
    if (Fw < Fw0) {
      W0 <- W
      Fw0 <- Fw
    }
  }
  W0
}

################################################################
#         1D solver for individual objective function          #
#         using function OptManiMulitBallGBB                   #
################################################################
ballGBB1D <- function(M, U, ...) {

  # Options for function OptManiMulitBallGBB
  opts <- list(...)
  W0 <- get_ini1D(M, U)
  if (is.null(opts$xtol) || opts$xtol < 0 || opts$xtol > 1) opts$xtol <- 1e-8
  if (is.null(opts$gtol) || opts$gtol < 0 || opts$gtol > 1) opts$gtol <- 1e-8
  if (is.null(opts$ftol) || opts$ftol < 0 || opts$ftol > 1) opts$ftol <- 1e-12
  # parameters for control the linear approximation in line search
  if (is.null(opts$rho) || opts$rho < 0 || opts$rho > 1) opts$rho <- 1e-04
  # factor for decreasing the step size in the backtracking line search
  if (is.null(opts$eta))
    opts$eta <- 0.2 else if (opts$eta < 0 || opts$eta > 1)
      opts$eta <- 0.1
  # parameters for updating C by HongChao, Zhang
  if (is.null(opts$gamma) || opts$gamma < 0 || opts$gamma > 1) opts$gamma <- 0.85
  if (is.null(opts$tau) || opts$tau < 0 || opts$tau > 1) opts$tau <- 1e-03
  # parameters for the  nonmontone line search by Raydan
  if (is.null(opts$m)) opts$m <- 10
  if (is.null(opts$STPEPS)) opts$STPEPS <- 1e-10
  if (is.null(opts$maxiter) || opts$maxiter < 0 || opts$maxiter > 2^20) opts$maxiter <- 800
  if (is.null(opts$nt) || opts$nt < 0 || opts$nt > 100) opts$nt <- 5
  # if (is.null(opts$record)) opts$record <- 0
  if (is.null(opts$eps)) opts$eps <- 1e-14

  # X <- OptManiMulitBallGBB(W0, opts, fun1D, M, U)$X
  fit <- OptManiMulitBallGBB(W0, opts, fun1D, M, U)
  X <- fit$X
  # return(X)
  list(X = X, W0 = W0, test_out = fit$test_out)
}

###########################################################################
#         Line search algorithm for optimization on manifold              #
###########################################################################
OptManiMulitBallGBB <- function(X, opts=NULL, fun, ...) {
  # Line search algorithm for optimization on manifold:
  #
  #    min f(X), s.t., ||X_i||_2 = 1, where X \in R^{n,p}
  #        g(X) = grad f(X)
  #    X = [X_1, X_2, ..., X_p]
  #    each column of X lies on a unit sphere

  # Input:
  #    X --- initialization. ||X_i||_2 = 1, each column of X lies on a unit sphere
  #    opts --- option structure with fields:
  #       maxiter     max number of iterations
  #       xtol        stop control for ||X_k - X_{k-1}||
  #       gtol        stop control for the projected gradient
  #       ftol        stop control for |F_k - F_{k-1}|/(1+|F_{k-1}|)
  #       usually, max{xtol, gtol} > ftol
  #    fun --- objective function and its gradient:
  #    [F, G] = fun(X, data1, data2)
  #
  #    F, G are the objective function value and gradient, repectively
  #    data1, data2 are addtional data, and can be more.
  #
  # Calling syntax:
  #    OptManiMulitBallGBB(X0, opts, fun, data1, data2);
  #
  # Output:
  #     x --- solution
  #     g --- gradient of x
  #     Out --- output information
  #
  # For example, consider the maxcut SDP:
  #     X is n by n matrix
  #     max Tr(C*X), s.t., X_ii = 1, X is PSD.
  #
  #     low rank model is:
  #         X = V'*V, V = [V_1, ..., V_n], V is a p by n matrix
  #         max Tr(C*V'*V), s.t., ||V_i|| = 1,
  #
  #     # Define the function returning objective and the gradient:
  #     maxcut_quad <- function(V, C){
  #       g = 2*(V*C)
  #       f = sum(dot(g,V))/2
  #       return(list(F = f, G = g))
  #     }
  #
  #     # Call function OptManiMulitBallGBB
  #     OptManiMulitBallGBB(x0, opts, maxcut_quad, C);
  #
  #
  #
  #     Reference: Z. Wen and W. Yin (2013), A feasible method for optimization
  #       with orthogonality constraints
  #

  ##Size information
  X <- as.matrix(X)
  if (length(X) == 0)
    print("input X is an empty") else {
      n <- dim(X)[1]; k <- dim(X)[2]}

  if (is.null(opts$xtol) || opts$xtol < 0 || opts$xtol > 1) opts$xtol <- 1e-8
  if (is.null(opts$gtol) || opts$gtol < 0 || opts$gtol > 1) opts$gtol <- 1e-8
  if (is.null(opts$ftol) || opts$ftol < 0 || opts$ftol > 1) opts$ftol <- 1e-12
  # parameters for control the linear approximation in line search
  if (is.null(opts$rho) || opts$rho < 0 || opts$rho > 1) opts$rho <- 1e-04
  # factor for decreasing the step size in the backtracking line search
  if (is.null(opts$eta))
    opts$eta <- 0.2 else if (opts$eta < 0 || opts$eta > 1)
      opts$eta <- 0.1
  # parameters for updating C by HongChao, Zhang
  if (is.null(opts$gamma) || opts$gamma < 0 || opts$gamma > 1) opts$gamma <- 0.85
  if (is.null(opts$tau) || opts$tau < 0 || opts$tau > 1) opts$tau <- 1e-03
  # parameters for the  nonmontone line search by Raydan
  if (is.null(opts$m)) opts$m <- 10
  if (is.null(opts$STPEPS)) opts$STPEPS <- 1e-10
  if (is.null(opts$maxiter) || opts$maxiter < 0 || opts$maxiter > 2^20) opts$maxiter <- 800
  if (is.null(opts$nt) || opts$nt < 0 || opts$nt > 100) opts$nt <- 5
  # if (is.null(opts$record)) opts$record <- 0
  if (is.null(opts$eps)) opts$eps <- 1e-14

  # copy parameters
  xtol <- opts$xtol
  gtol <- opts$gtol
  ftol <- opts$ftol
  rho  <- opts$rho
  m <- opts$m
  STPEPS <- opts$STPEPS
  eta <- opts$eta
  gamma <- opts$gamma
  eps <- opts$eps
  nt <- opts$nt
  crit <- matrix(1, opts$maxiter, 3)
  # record <- opts$record

  # normalize x so that ||x||_2 = 1
  # nrmX <- colSums(X*X)
  ##
  nrmX <- apply(X*X, 2, sum)
  ##
  ##
  test_out <- NULL
  test_out$nrmX <- nrmX
  ##
  nrmX <- matrix(nrmX, 1, k)
  if (sqrt(sum((nrmX-1)^2)) > 1e-8) {
    X <- sweep(X, 2, sqrt(nrmX),"/")
  }
  args = list(X, ...)
  eva <- do.call(fun, args)
  f <- eva$F; g <- as.matrix(eva$G)
  ##
  test_out$f <- f
  test_out$g <- g
  ##
  out <- c()
  out$nfe <- 1


  # Xtg <- colSums(X*g)
  ##
  Xtg <- apply(X*g, 2, sum)
  ##
  Xtg <- matrix(Xtg, 1, k)
  # gg <- colSums(g*g)
  ##
  gg <- apply(g*g, 2, sum)
  ##
  gg <- matrix(gg, 1, k)
  # XX <- colSums(X*X)
  ##
  XX <- apply(X*X, 2, sum)
  ##
  XX <- matrix(XX, 1, k)
  XXgg <- XX*gg
  temp <- sweep(X, 2, Xtg, "*")
  dtX <- matrix(temp, n, k) - g
  nrmG <- sqrt(sum((dtX)^2))

  ##
  test_out$dtX <- dtX
  test_out$nrmG <- nrmG
  ##

  Q <- 1; Cval <- f; tau <- opts$tau

  # ## print iteration header if debug == 1
  # if (record >= 1){
  #     cat(paste('------ Gradient Method with Line search ----- ',"\n"),
  #         sprintf("%4s %8s %8s %10s %10s", 'Iter', 'tau', 'F(X)', 'nrmG', 'XDiff'))
  # }
  # if (record == 10) out$fvec = f

  ##
  X_list <- vector("list", opts$maxiter)
  ##
  ##main iteration
  for (itr in 1:opts$maxiter) {
    Xp <- X; fp <- f; gp <- g; dtXP <- dtX

    nls <- 1; deriv = rho*nrmG^2

    while (TRUE) {
      ## calculate g, f
      tau2 <- tau/2
      beta <- (1 + (tau2^2)*(-(Xtg^2) + XXgg))
      a1 <- ((1 + tau2*Xtg)^2 - (tau2^2)*XXgg)/beta
      a2 <- -tau*XX/beta
      X <- sweep(Xp, 2, a1, "*") + sweep(gp, 2, a2, "*")


      args = list(X, ...)
      eva <- do.call(fun, args)
      f <- eva$F; g <- as.matrix(eva$G)
      out$nfe <- out$nfe + 1

      if (f <= Cval - tau*deriv || nls >= 5)
        break
      tau <- eta * tau
      nls <- nls + 1
    }
    ##
    X_list[[itr]] <- X
    ##

    # if (record == 10)
    #   out$fvec <- rbind(out$fvec,f)

    #Xtg <- sapply(1:k, function(d) sum(X[,d]*g[,d]))
    # Xtg <- colSums(X*g)
    ##
    Xtg <- apply(X*g, 2, sum)
    ##
    Xtg <- matrix(Xtg, 1, k)
    # gg <- colSums(g*g)
    ##
    gg <- apply(g*g, 2, sum)
    ##
    gg <- matrix(gg, 1, k)
    # XX <- colSums(X*X)
    ##
    XX <- apply(X*X, 2, sum)
    ##
    XX <- matrix(XX, 1, k)
    XXgg <- XX*gg
    temp <- sweep(X, 2, Xtg, "*")
    dtX <- matrix(temp, n, k) - g

    nrmG <- sqrt(sum(dtX^2))
    s <- X - Xp
    XDiff <- sqrt(sum(s^2))/sqrt(n)
    FDiff <- abs(fp - f)/(abs(fp) + 1)

    # if (record >= 1)
    #   cat(paste('------ Gradient Method with Line search ----- ',"\n"),
    #       sprintf("%4s %8s %8s %10s %10s %10s", 'Iter', 'tau', 'F(X)', 'nrmG', 'XDiff','nls'))

    crit[itr,] <- cbind(nrmG, XDiff, FDiff)
    r <- length((itr - min(nt, itr)+1):itr)
    temp1 <- matrix(crit[(itr - min(nt, itr)+1):itr,], r, 3)
    # mcrit <- colMeans(temp1)
    ##
    mcrit <- apply(temp1, 2, mean)
    ##


    if ((XDiff < xtol && FDiff < ftol) || nrmG < gtol
        || all(mcrit[2:3] < 10 * c(xtol, ftol))) {
      out$msg = "converge"
      break
    }

    y <- dtX - dtXP
    sy <- sum(s*y)
    tau <- opts$tau
    sy <- abs(sy)

    if (sy > 0) {
      if (itr %% 2 == 0)
        tau <- sum(s*s)/sy else { tau <- sy/sum(y*y)}

      tau <- max(min(tau, 1e+20), 1e-20)
    }
    Qp <- Q; Q <- gamma*Qp + 1
    Cval <- (gamma*Qp*Cval + f)/Q
  }

  if (itr >= opts$maxiter)
    out$msg <- "exceed max iteration"

  # Xn <- colSums(X*X)
  ##
  Xn <- apply(X*X, 2, sum)
  ##
  Xn <- matrix(Xn, 1, k)
  out$feasi <- svd(Xn - 1)$d[1]

  ##
  test_out$X_list <- X_list
  test_out$X <- X
  ##

  if (out$feasi > eps) {
    # nrmX <- colSums(X*X)
    ##
    nrmX <- apply(X*X, 2, sum)
    ##
    X <- sweep(X, 2, sqrt(nrmX),"/")
    args = list(X, ...)
    eva <- do.call(fun, args)
    f <- eva$F; g <- as.matrix(eva$G)
    out$nfe <- out$nfe + 1
    # nrmX.n <- colSums(X*X)
    ##
    nrmX.n <- apply(X*X, 2, sum)
    ##
    out$feasi <- svd(nrmX.n - 1)$d[1]
  }

  out$nrmG <- nrmG
  out$fval <- f
  out$itr <- itr

  # return(list(X = X, g = g, out = out))
  ##
  return(list(X = X, g = g, out = out, test_out = test_out))
  ##
}
